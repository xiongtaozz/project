- 7个mysql表格，用于持久化数据
- 用四个爬虫分别爬取了：代售点、站点与乘降所信息、列车时刻表、余票信息
- 中间件：filter，用url+turn值去重；middle，抛弃不在本轮的过期request。
- 流水线：持久化item到数据库中。
- 脚本：初次启动，依次启动爬虫，以后后面的爬虫依赖于前面的爬虫；持久运行爬虫，并根据轮次启动爬虫更新数据。
- settings：在每个爬虫中配置中间件与流水线。在总settings.py中设置log的级别以及导出的日志文件。
